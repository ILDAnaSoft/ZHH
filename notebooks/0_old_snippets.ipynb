{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, os\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "from zhh import parse_sample_path, get_preselection_passes, ProcessIndex\n",
    "\n",
    "DATA_ROOT = f'/nfs/dust/ilc/user/bliewert/zhh'\n",
    "INDEX_DIR = '/nfs/dust/ilc/user/bliewert/zhh/CreateRawIndex/v1'\n",
    "\n",
    "processes = np.load(f\"{INDEX_DIR if os.name != 'nt' else REPO_ROOT}/processes.npy\")\n",
    "samples = np.load(f\"{INDEX_DIR if os.name != 'nt' else REPO_ROOT}/samples.npy\")\n",
    "chunks = np.load(f'{DATA_ROOT}/CreatePreselectionChunks/v1/chunks.npy') if os.name != 'nt' else np.load(f'{REPO_ROOT}/chunks_f.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = chunks_f[chunks_f['chunk_size_factual'] <= 0]\n",
    "if len(subset) > 0:\n",
    "    raise Exception(f\"Invalid chunk length mismatch for branch <{subset['branch']}>\")\n",
    "else:\n",
    "    print('Chunks OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduce indices on samples and processes (included in future runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_sample = ProcessIndex.dtype_sample\n",
    "dtype_process = ProcessIndex.dtype_process\n",
    "\n",
    "if not 'sid' in samples.dtype.names:\n",
    "    samples_new = np.empty(len(samples), dtype=dtype_sample)\n",
    "    samples_new['sid'] = np.arange(len(samples))\n",
    "    for col in samples.dtype.names:\n",
    "        samples_new[col] = samples[col]\n",
    "        \n",
    "    if len(samples) == len(samples_new):\n",
    "        np.save(f'{INDEX_DIR}/samples.npy', samples_new)\n",
    "\n",
    "if not 'pid' in processes.dtype.names:\n",
    "    #processes_new = np.array([pids, *(processes[col] for col in processes.dtype.names)], dtype=dtype_process)\n",
    "    processes_new = np.empty(len(processes), dtype=dtype_process)\n",
    "    processes_new['pid'] = np.arange(len(processes))\n",
    "    for col in processes.dtype.names:\n",
    "        processes_new[col] = processes[col]\n",
    "\n",
    "    if len(processes) == len(processes_new):\n",
    "        np.save(f'{INDEX_DIR}/processes.npy', processes_new)\n",
    "        \n",
    "print('Conversion successful')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prototyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval as make_tuple\n",
    "import json\n",
    "\n",
    "def test_meta_files(DATA_ROOT:str=f'{DATA_ROOT}/PreselectionFinal/{version}')->bool:\n",
    "    files = glob(f'{DATA_ROOT}/*_Source.txt')\n",
    "    #branches = list(map(lambda x: x.split(f'{DATA_ROOT}/')[1].split('_Source.txt')[0], files))\n",
    "\n",
    "    for f in tqdm(files):\n",
    "        branch = f.split(f'{DATA_ROOT}/')[1].split('_Source.txt')[0]\n",
    "        \n",
    "        if osp.isfile(f'{DATA_ROOT}/{branch}_FinalStateMeta.json'):\n",
    "            with open(f, 'r') as file:\n",
    "                src_spec = file.read()\n",
    "                if src_spec.startswith('('):\n",
    "                    src_file, chunk_start, chunk_end = make_tuple(src_spec)\n",
    "                else:\n",
    "                    src_file = src_spec\n",
    "            \n",
    "            # Read metadata\n",
    "            with open(f'{DATA_ROOT}/{branch}_FinalStateMeta.json', 'r') as file:\n",
    "                meta = json.load(file)\n",
    "\n",
    "            n_gen = meta['nEvtSum']\n",
    "            proc = meta[\"processName\"]\n",
    "            \n",
    "            if proc == '' or n_gen == 0:\n",
    "                print(src_file)\n",
    "                raise Exception(branch)\n",
    "    \n",
    "    return True\n",
    "\n",
    "test_meta_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete invalid branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for branch in chunks_f['branch'][chunks_f['branch'] >= 15497]:\n",
    "    post_files_suffixes = ['_PreSelection_llHH.root', '_PreSelection_vvHH.root', '_PreSelection_qqHH.root', '_FinalStates.root', '_FinalStateMeta.json', '.slcio', '_Source.txt']\n",
    "    \n",
    "    for suffix in post_files_suffixes:\n",
    "        pass\n",
    "        #os.remove(f'{DATA_ROOT}/PreselectionFinal/v1/{branch}{suffix}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
